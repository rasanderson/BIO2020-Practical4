---
title: 'Practical 4: Generalised Linear Models'
author: "Bio2020"
output: word_document
---
# Introduction
Generalised linear models (GLMs) are, as their name suggests, an extension of the standard linear model. They still work to the same framework of a response variable, and one or more explanatory variables. The difference is that they can be much more flexible in the type of response variable you are working with. In a conventional linear model it is assumed that your response variable can take any value, e.g. 4.65, 1.98, -4.32, 65.0, 9241.2 etc. These represent a "normal" distribution or bell-shaped curve; you will also see a normal distribution called a "Gaussian" distribution, after the German mathematician Carl Gauss who first described it. Of course in "real" biological data, some of these values would not make any sense. You might have:

* **Binary data** Presence / Absence, Dead / Alive, Diseased / Healthy, Mutant / Wild Type etc.
* **Count data** Number of birds in different gardens, counts of pollinators visiting flowers, number of muscle reflexes in response to electical stimuli etc.
* **Positive numbers only** Heights of oak trees, weights of brown rats, yield of crops etc. These numbers might have decimal places, but they cannot be negative
* **Proportion or percentages** These are "bounded" numbers, between 0 and 1.0, or 0 and 100 respectively.

If you use a conventional linear model with these types of data, when you check the model assumptions, especially via a QQ plot, you may observe distortions, suggesting the linear model is not valid. You can sometimes transform your data before analysis by a linear model, for example take the `log(number_of_birds + 1)` as a response variable (we include the `+ 1` as it is not possible to take a logarithm of zero). However, it is usually better to use a generalised linear model from the outset.

A linear model works best with normal (Gaussian) data, but a GLM can be extended to a wide range of data types, including all four described above. To remind yourself of the underlying theory of GLMs go to [This Interactive Website](https://naturalandenvironmentalscience.shinyapps.io/generalised_linear_models/) and we will begin by using some of the examples from that website.

The overall aim of this practical is to help you have a better understanding of GLMs, how to set them up in R/RStudio, and learn how to interpret their outputs. Specific objectives of Practical 4 are:

1. Use of GLMs with counts (whole number response data)
2. Use of GLMs with binary responses (presence / absence, dead / alive etc.)
3. Explore these concepts with new datasets
4. Consider lognormal response data (response positive numbers, e.g. weight, height)

## Setting up for the practical  

First, go to Canvas and download the **lichen.csv** and **sppcount.csv** data sets and save them to your **Data** folder in the **BIO2020** folder where you have your R project stored.  

Second, start RStudio, and click on **File -> Recent Projects** and select the BIO2020 project.

Finally, create a new R script by clicking on **File -> New File -> R Script**. Save this file into your BIO2020 folder, calling it _**Practical_4.R**_ **Note** If your PC/MacBook is configured so that the full filenames are not displayed, which is often the default, then simply call your new script **_Practical_4_** when prompted.

## Initial lines in your script

As usual, begin your script with a useful comment, and then load the `bio2020` package. If you have not managed to install it, please load the `mosaic` package.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Practical 4. Exploration of data using generalised linear models

# Load up essential libraries before beginning
library(bio2020)

```

#### Importing data from .csv files into R 
Now load in the two .csv files you downloaded from  Canvas. `lichen.csv` and `sppcount.csv` at the very beginning of the practical. **Note**: Remember to move the two files into your **`Data`** folder before using `read.csv()` to import them into R.

```{r echo=TRUE,  message=FALSE, warning=FALSE}
lichen_dat <- read.csv("Data/lichen.csv")
sppcount_dat <- read.csv("Data/sppcount.csv")
```


# 1. GLMs with counts data
## 1.1 Counts of numbers of aquatic invertebrate species
Aquatic invertebrates provide very useful bioindicators of river systems. A pollution event might be short-lived, and pollutants in the water only detectable for a few days after a spillage. However the effects on the aquatic invertebrates can be detectable for days, weeks or months. They are used by the UK's Environment Agency, Defra, Scottish, Welsh and NI governments to assess aquatic pollution through a system known as RIVPACS [see their website here for more details](https://www.ceh.ac.uk/services/rivpacs-reference-database).

## 1.2 Summary Statistics and visualisation of aquatic invertebrate data
It is always good to start by observing the data and running some summary statistics. The data are are two columns of data, recording both the numbers of aquatic invertebrate species, and the water pollution levels, at 30 rivers.

```{r echo=TRUE, include=TRUE}
# Check the top of your data, and overall summary
head(sppcount_dat)
summary(sppcount_dat)
str(sppcount_dat)
```

After looking at the data, what do you think is the response and what is the explanatory variable? **Hint**: think about "cause" and "effect". When plotting your data, what would go on your x-axis, and which variable on your y-axis. Notice also that the `str()` function which returns the "structure" of the data, records `pollution` as numeric (`num`) and species as integer (`int`). An integer is a whole number, i.e. 6, 8, 12 with no decimal points.

```{r}
mean(~pollution, data=sppcount_dat) # Overall average pollution
mean(~species, data=sppcount_dat)   # Overall average number of species at all the rivers
sd(~species, data = sppcount_dat)   # Overall standard deviation of the species number
sd(~pollution, data = sppcount_dat) # Overall standard deviation of the pollution
```

Notice that in the above commands we are calculating the overall mean and sd for species count and pollution. Thus the format of the call can be `mean(~pollution, data=sppcount_dat)`. Why might `mean(species ~ pollution, data=sppcount_dat)` **not** be appropriate to work out the average number of species at each pollution level? **Hint:** Is pollution a continuous or categorical explanatory variable? Try the command and see what you get.

Now let's visualise the data. Recall your graph-plotting skills from the previous practicals, and try and create a scatter plot similar to the following:

**Hints**

* Build up your scatter plot one line at a time, with `gf_point()` the first line, with the correct formula and dataset specified. Make sure in your formula you have the response (left-hand side of `~` symbol) and explanatory variable the right way round.
* Use the `%>%` or "THEN" symbol at the end of the first and subsequent lines before adding new ones
* On your second line, refine your labels with `gf_labs()`
* On your third line, add a fitted linear model line using `gf_lm()`. The plot below also includes the 95% confidence intervals for this fitted line. Use `?gf_lm` to read the help page to work out how to use the `interval` option to the function
* finally `gf_refine()` to refine your graph using a different theme such as `theme_bw()` or as here `theme_classic()`


```{r, echo=FALSE}
#Visualise with scatter points

gf_point(species~pollution, data = sppcount_dat) %>% 
  gf_labs(x = "Aquatic pollution level (mg/l)", y="Number of invertebrate species") %>% 
  gf_lm(interval = "confidence") %>% 
  gf_theme(theme_classic())

```

The plot above shows a clear link between the total number of aquatic invertebrate species and the amount of pollution present in the water. Visualisation is insufficient to test our (null) hypothesis that there about relationships between pollution and number of species. We need a formal statistical model. We will begin by doing it the "wrong" way with a linear model, and diagnose what is incorrect. **Note**: Look carrefully at the graph you have just created, and you might already be able to detect a potential problem. What is it?

## 1.3 Incorrect analysis via linear model
For the linear model we simply set our count of the number of species as the response, and pollution level as the explanatory in the usual way. Go ahead and store the results of your `lm()` call in an R object called `sppcount_lm`, and produce a summary of the results. Check that you get the following:


```{r, echo=FALSE}
sppcount_lm <- lm(species ~ pollution, data=sppcount_dat)
```
  
```{r echo=FALSE}
summary(sppcount_lm)

```

As you would expect, the model is highly significant, with a negative (significant) gradient for slope of -2.57, in other words for every 1 mg/l increase in pollution there is a decline in the number of species by about 2.57. When there is no pollution the number of species is about 29, which matches the graph you have just plotted above, when the horizontal axis of pollution is at zero.  There are two major problems however, the second of which you may already have spotted:

### 1.3.1 Have model assumptions been broken?
You will recall that linear models assume your data (or more precisely, the noise or errors around your fitted line) come from a normal or Gaussian distribution. The easiest way to check this is via a QQ plot:

```{r}
sppcount_lm_resid <- residuals(sppcount_lm)

gf_qq(~sppcount_lm_resid) %>% 
  gf_qqline()

```

There seems to be a strong S-bend in the QQ plot, hinting that there might be problems with the model and its assumptions are not satisfied.

### 1.3.1 What are the predicted numbers of species in heavily polluted rivers?
Hopefully you have already detected that this is a fundamental problem, simply by looking at your original graph of the data, with the straight line of the number of species added. What, for example, is the predicted number of species when water pollution is at 12 mg/l ?  Let's work it out:


```{r}
# Create a predictor function
lm_species_predictor <- makeFun(sppcount_lm)

# Obtain predicted value at 12 mg/l
lm_species_predictor(12)

```

Uh oh! We seem to be predicting a **negative** number of species, but we know that this is biological nonsense. The minimum value we should get is zero.

## 1.4 GLM and Simeon Poisson to the rescue...
GLMs are much more flexible, and we can use them to produce a much better and biologically meaningful model. Simeon Poisson was an early 19th Century French mathematician devised a distribution that handled count rather than continuous data. See [This interactive website](https://naturalandenvironmentalscience.shinyapps.io/generalised_linear_models/#section-poisson-and-binomial-distributions) to view the Poisson distribution. When the website loads, the distribution initially looks like a normal distribution, but with whole numbers. It has one parameter $\lambda$ (Greek letter lambda). Move the slider. You will notice that the distribution never contains values less than zero.

Let's now change from a linear model to a generalised linear model. If we simply replace `lm()` with `glm()` we will actually get the same results as before, because it defaults to using a normal distribution. However, if we use the `family` option we can specify that we want a Poisson distribution. Try the following and check your results match:


```{r echo=TRUE, include=TRUE}
sppcount_glm <- glm(species ~ pollution, data = sppcount_dat, family = poisson)
summary(sppcount_glm)

```

You can see that both the intercept and the (gradient) for pollution are highly significant. You will also notice that the wording and column headings are slightly different from your linear model. Linear models use a technique known as "least squares" to estimate parameters, whereas generalised linear models use a method called "maximum likelihood", so the underlying mathematics differ.

So now what does this all mean. 

* **deviance** is the term used for variation in your data points
* The **deviance residuals** line gives a summary of the min, max, mean of all this variation after the model has been fitted, in other words a summary of the noise for all 30 rivers.
* The **coefficients** are your **explanatory** variables (i.e. pollution). You may notice that there are two coefficients when our model only specified one.

 - `(Intercept)` As usual, this is the predicted number of species when your explanatory variable (pollution) is zero. Here the estimated value for this is 3.43, which seems very low, but keep reading.
 - `pollution` this is the change in your number of species with increasing pollution, which is negative, reflecting a decline in biodiversity with pollution. However, the value of -0.139 probably seems a bit odd
- instead of t-statistics, maximum likelihood methods such as GLM produce z-statistics, which can be interpreted in a similar way to produce p-values. Both p-values are extremely low. Remember that `7.79-e13` is shorthand for `0.000000000000779` which you would write as `p<0.001` in a report.

* The **residual deviance** is a measure of how good your model is. If your residual deviance value is close to zero, then the model is not very good. 
* The **AIC** value is used when comparing two similar models, the lower the AIC, the better the model.
* Finally, the **Fisher score** is a measure of how many iterations of the model R ran looking at different estimates before displaying the results. 

There is a lot of information in the output and it is easy to get overwhelmed. The main things to note are the `Estimate` values, and when you report them in a table you would typically quote their associated z and p statistics, along with the overall AIC.

#### What about the strange Estimates from the GLM?
As we noted above, the values of 3.43 and -0.139 do not quite match what was expected. Indeed, looking at your original graph, an estimated number of species of only 3.43 when the water is unpolluted (x-axis at zero) does not match your graph where it looks to be around 29 or 30 species! This is because GLMs use what is known as a "link function" in their calculations; if you are interested see the [How to generalise page from the interactive website](https://naturalandenvironmentalscience.shinyapps.io/generalised_linear_models/#section-how-to-generalise). Poisson GLMs use natural logarithms as their link function, so we would need to take the antilog, or exponential, to get back to the original units. Let's check with the expected number of species when pollution is zero, i.e. the intercept:

```{r}
exp(3.43)
```

That looks more sensible. To finish off, we will check the model assumptions, predict the number of species when pollution is 12 mg/l and replot our original graph, but with a GLM rather than linear model.

### 1.4.1 Check Poisson GLM model assumptions
As before, create a QQ plot of the residuals. Copy, paste and edit your original `gf_qq()` and `gf_line()` code in your `Practical_4.R` script to save time typing. You should end up with a graph similar to this:

```{r, echo=FALSE}
sppcount_glm_resid <- residuals(sppcount_glm)

gf_qq(~sppcount_glm_resid) %>% 
  gf_qqline()
```

Although there is still a slight S-bend in the scatter of points, it is nothing like as severe a problem as we had with the linear model of the same data.

### 1.4.2 What is the predicted number of species in heavily polluted streams with the GLM?
With the linear model we had the problem that our model could predict negative numbers of species in polluted water. What do we get with the GLM? Modify your `makeFun()` call to create a new predictor function, and see if you get this value for 12 mg/l pollution?

```{r, echo=FALSE}
# Create a predictor function
glm_species_predictor <- makeFun(sppcount_glm)

# Obtain predicted value at 12 mg/l
glm_species_predictor(12)

```

Although the biodiversity is obviously very low, it is still positive, which makes more sense.

### 1.4.3 Modify scatterplot of original data to show Poisson GLM
Our original scatter plot had a straight line from the `gf_lm()` function. Instead, we will add a curve from our GLM model, using `gf_smooth()`. This function has several methods for creating curves, and we specify that we used a GLM, with Poisson errors, and gives a smooth curve. **Build the following graph up slowly**, one line at a time, re-creating it each time, so you understand what each command does:

```{r}
gf_point(species ~ pollution, data=sppcount_dat) %>% 
  gf_labs(x = "Aquatic pollution level (mg/l)", y="Number of invertebrate species") %>% 
  gf_smooth(method="glm", method.args = list(family="poisson"), se=TRUE) %>% 
  gf_refine(theme_classic())
```



## 2. GLMs with Binary Data
Your experiment may produce categorical response data, e.g. male or female, wilted or turgid, infected or uninfected, dead or alive. Note that a response such as simply 'dead' or 'alive' differs from a response where you have counts of the numbers of dead or alive out of your original sample. So binary data can have two slightly different forms:

* Simple presence / absence; dead / alive; 0 / 1 data (binary response)
* Information about sample size. e.g. number of eggs that hatch, out of egg clutches that vary slightly in their size between nests.

The latter has more information (and is proportion data) so can be analysed slightly differently, but both use the **binomial distribution**, see [this page of the Interactive website](https://naturalandenvironmentalscience.shinyapps.io/generalised_linear_models/#section-poisson-and-binomial-distributions). In the simple binary response the sample size, shown as "Size of each trial" on the interactive graph on the website, is 1. In the second type of scenario, the sample size would vary depending on for example the size of each egg clutch in different nests.

In this practical we will focus on the simpler type of data, where you just have a binary response. We will use the data `lichen_dat` that you read into R at the start of this practical. In this example, you are testing the effect of atmospheric pollution on the presence or absence of lichen on trees. Lichens have been found to be very sensitive biological indicators of atmospheric pollution. As lichen presence can be affected by the tree bark, particularly calcium content, this was also measured. Your response is a 1 or 0, where 1 indicates lichen are present and 0 lichen absent. 

## 2.1 Summary statistics and visualisation of lichen data

Start with some visualisation and summary statistics. What do the plots bellow tell you about lichen ecology? Can you form some initial assumptions based on what they show?  


```{r echo=TRUE, include=TRUE}
summary(lichen_dat)
str(lichen_dat)
```

Before we continue, notice that calcium and air pollution are continuous variables, indicated by `num` in the structure of the data. However `lichen` is showing as a `int` or whole-number integer, and the summary is giving a mean value of 0.58 for the lichens. This is a little misleading, as really the lichens are a categorical binary response. We can force R to recognise this by using the `as.factor()` function. Remember we use the `$` symbol to allow us to refer to a single column:

```{r}
lichen_dat$lichen_fct <- as.factor(lichen_dat$lichen)
summary(lichen_dat)
str(lichen_dat)
```

You can see that the `summary` function has a new variable called `lichen_fct` which will be more convenient for some plots. Let's begin with a scatter-plot of the observed points against the two explanatory variables:

```{r}
# This uses the multi_plot() function from bio2020 to plot them side-by-side
# If you do not have bio2020 available, do not assign them to plt1 or plt2, but
# simply run the gf_point() functions to display the graphs in the plot window
lichen_plt1 <- gf_point(lichen ~ calcium, data=lichen_dat) 
lichen_plt2 <- gf_point(lichen ~ airpoll, data=lichen_dat)
multi_plot(lichen_plt1, lichen_plt2, cols=2)
```

The problem with these two plots is whilst you can see that there appears to be more lichens when at higher calcium and lower air pollution, the plots are actually of limited value for exploratory data visualisation. Boxplots or violinplots would be more useful. Of course, by default they place the categorical explanatory variable on the horizontal axis, and the continuous response variable on the vertical axis. We can get round this problem by flipping our boxplots or violin plots through 90-degrees, so that the lichens still appear on the vertical axis, as we would expect for a response variable. We can do this with the `coord_flip()` option to `gf_refine()`. Both boxplots and violinplots expect categorical variables (factors) so we will use `lichen_fct` in their call.

Let's create a simple boxplot first to show the idea. As usual, build it up one line at a time:

```{r}
gf_boxplot(calcium ~ lichen_fct, data=lichen_dat) %>% 
  gf_refine(coord_flip())  # In reality, lichen is response, calcium the explanatory, so flip
```

To show you the level of information that can be displayed this way, including the original data points, let's create two violinplots. I've added `gf_theme(theme_classic())` to change the overall appearence. You don't really need a separate legend for this plot, as it is fairly obvious what the two groups are, so `legend.position="none"` has been included. All these polishes to the graph are entirely optional. All you really need are the first two lines `gf_violin()` and `gf_refine(coord_flip())`.

```{r, eval=FALSE}
gf_violin(calcium ~lichen_fct, data = lichen_dat, alpha = 0.3, fill = ~lichen_fct) %>% 
  gf_refine(coord_flip())  %>% 
  gf_sina() %>% 
  gf_labs(x = "Lichen", y = "Calcium", title = "Lichen and Calcium") %>% 
  gf_theme(theme_classic()) %>% 
  gf_theme(legend.position="none") 

gf_violin(airpoll~lichen_fct, data = lichen_dat, alpha = 0.3, fill = ~lichen_fct) %>% 
  gf_refine(coord_flip())  %>% 
  gf_sina() %>% 
  gf_labs(x = "Lichen", y = "Air Pollution", title = "Lichen and Pollution") %>% 
  gf_theme(theme_classic()) %>% 
  gf_theme(legend.position = "none")

```

Once you have created the plots, try storing them in `lichen_plt3` and `lichen_plt4` objects, and display them side-by-side using `multi_plot()` (requires `bio2020` package):

```{r, echo=FALSE}
p3 <- gf_violin(calcium ~lichen_fct, data = lichen_dat, alpha = 0.3, fill = ~lichen_fct) %>% 
  gf_refine(coord_flip())  %>% 
  gf_sina() %>% 
  gf_labs(x = "Lichen", y = "Calcium", title = "Lichen and Calcium") %>% 
  gf_theme(theme_classic()) %>% 
  gf_theme(legend.position="none") 

p4 <- gf_violin(airpoll~lichen_fct, data = lichen_dat, alpha = 0.3, fill = ~lichen_fct) %>% 
  gf_refine(coord_flip())  %>% 
  gf_sina() %>% 
  gf_labs(x = "Lichen", y = "Air Pollution", title = "Lichen and Pollution") %>% 
  gf_theme(theme_classic()) %>% 
  gf_theme(legend.position = "none")

multi_plot(p3, p4, cols=2)

```

Displaying your data this way gives you a much better insight into the relationships between the response variable of lichen, and explanatory of air pollution or calcium, whilst still adhering to the convention of placing your **response on the vertical** axis, and the **explanatory on the horizontal** axis.

## 2.2 GLMs with binary response variable
### 2.2.1 Interaction terms in linear models and generalised linear models
Here we have two explanatory variables, calcium and air pollution. We cannot assume that they are independent in their effects, and they may **interact** in some way in terms of their impact on the presence or absence of lichens. You have already covered interaction terms in Practical 3, and remind yourself of how they work at [interactive website explaining interaction terms](https://naturalandenvironmentalscience.shinyapps.io/multiple_explan/#section-interactions-between-explanatory-variables)

When a GLM contains a `:` in the explanatory variables, such as

`glm(response ~ explan1 + explan2 + explan1:explan2, data = data, family = family)`

it means that the model will test to see if an interaction between the two variables is having a significant effect. It also tests the individual "main effects" of `explan` and `explan2`. There is also a shortcut for the above structure in that if you use `*` all the main effects and interactions will be tested. Thus:

`glm(response ~ explan1 + explan2 + explan1:explan2, data = data, family = family)`

and

`glm(response ~ explan1*explan2, data = data, family = family)`

are identical. The latter type of structure to call either linear or generalised linear models with interactions can save you having to type all the main effects separately, and is especially useful with e.g. 3 (or more) explanatory variables.

This results in all covariate being examined individually but also as groups such as this (notice the three way interaction):

|   -covariate1 results  
|   -covariate2 results   
|   -covariate3 results  
|   -covariate1:covariate2 results  
|   -covariate1:covariate3 results  
|   -covariate2:covariate3 results  
|   -covariate1:covariate2:covariate3 results  

We will begin by running a full model including, the interaction terms; however, these can be removed later if not necessary. Notice that the family for this model has been changed as we now have a binary response variable. 

```{r echo=TRUE, include=TRUE}

lichen_glm1 <- glm(lichen ~ airpoll + calcium + airpoll:calcium, data = lichen_dat, family = binomial)
summary(lichen_glm1)

```

If the model is **over-fitted or saturated**, it would not be a valid model as it would fit the data perfectly. You can easily see if this is the case by looking at the summary. If there are zero residual degrees of freedom, and the residual deviance is also zero (on your PC the zero may be expressed in exponential format due to rounding), then the model is oversaturated and not a good fit. The model is not overdispersed, but none of the predictors are significant. Next fit a simpler model, with only main effects and without the interaction term, and compare the two. 

```{r echo=TRUE, include=TRUE}
lichen_glm2 <- glm(lichen ~ airpoll + calcium, data = lichen_dat, family = binomial)
summary(lichen_glm2)

```

Notice now that the main covariates are significant after removing the interaction term. Also, the **AIC** value is lower in the second model meaning this model is an improvement over the more complex one we ran earlier. What do the results of this simpler model tell you about lichen and its relationship with calcium and air pollution?